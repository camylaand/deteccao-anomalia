{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camylaand/deteccao-anomalia/blob/main/Segundo_modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKetB_WHMgsW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"modelos\", exist_ok=True)\n",
        "\n",
        "!mv scaler.pkl modelos/\n",
        "!mv colunas_scaler.pkl modelos/\n",
        "!mv modelo_encoder.keras modelos/\n",
        "!mv modelo_autoencoder.keras modelos/\n",
        "!mv kmeans_auto.pkl modelos/\n",
        "!mv encoder_tipo_transacao.pkl modelos/\n",
        "!mv encoder_semana.pkl modelos/\n",
        "!mv encoder_horario.pkl modelos/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhS0HI38Mkoj",
        "outputId": "cabebe60-2518-430b-f4b9-3f9f7e31b071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn joblib tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Suprimir aviso do XGBoost\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='xgboost')\n",
        "\n",
        "# ----------------------\n",
        "# Carregamento de modelos\n",
        "# ----------------------\n",
        "def carregar_modelos():\n",
        "    modelos = {\n",
        "        \"scaler\": joblib.load(\"modelos/scaler.pkl\"),\n",
        "        \"colunas_scaler\": joblib.load(\"modelos/colunas_scaler.pkl\"),\n",
        "        \"encoder_model\": load_model(\"modelos/modelo_encoder.keras\", compile=False),\n",
        "        \"autoencoder\": load_model(\"modelos/modelo_autoencoder.keras\", compile=False),\n",
        "        \"kmeans\": joblib.load(\"modelos/kmeans_auto.pkl\"),\n",
        "        \"encoder_tipo\": joblib.load(\"modelos/encoder_tipo_transacao.pkl\"),\n",
        "        \"encoder_semana\": joblib.load(\"modelos/encoder_semana.pkl\"),\n",
        "        \"encoder_horario\": joblib.load(\"modelos/encoder_horario.pkl\")\n",
        "    }\n",
        "    return modelos\n",
        "\n",
        "# ----------------------\n",
        "# Cálculo de erro e distância\n",
        "# ----------------------\n",
        "def calcular_erros_e_distancias(df, modelos):\n",
        "    colunas_scaler = modelos[\"colunas_scaler\"]\n",
        "    X_escalado = modelos[\"scaler\"].transform(df[colunas_scaler])\n",
        "    reconstruido = modelos[\"autoencoder\"].predict(X_escalado)\n",
        "    df[\"erro_reconstrucao\"] = np.mean(np.square(X_escalado - reconstruido), axis=1)\n",
        "\n",
        "    cod_latente = modelos[\"encoder_model\"].predict(X_escalado)\n",
        "    dist = euclidean_distances(cod_latente, modelos[\"kmeans\"].cluster_centers_)\n",
        "    df[\"distancia_cluster\"] = np.min(dist, axis=1)\n",
        "    return df\n",
        "\n",
        "# ----------------------\n",
        "# Geração da coluna 'fraude_confirmada' com pesos\n",
        "# ----------------------\n",
        "def detectar_anomalias(df, modelos):\n",
        "    df['transacao_data'] = pd.to_datetime(df['transacao_data'], errors='coerce')\n",
        "    df = df.sort_values(['conta_id', 'transacao_data'])\n",
        "\n",
        "    df['media_valor'] = pd.to_numeric(df['media_valor'], errors='coerce')\n",
        "    df['std_valor'] = pd.to_numeric(df['std_valor'], errors='coerce')\n",
        "    df['transacao_valor'] = pd.to_numeric(df['transacao_valor'], errors='coerce')\n",
        "\n",
        "    df['tempo_desde_ultima'] = df.groupby('conta_id')['transacao_data'].diff().dt.total_seconds()\n",
        "\n",
        "    df['regra_valor_alto'] = (df['transacao_valor'] > (df['media_valor'] + 3 * df['std_valor'])).astype(int)\n",
        "    df['regra_horario'] = (df['faixa_horaria_Madrugada'] == 1).astype(int)\n",
        "    df['regra_frequencia'] = (df['tempo_desde_ultima'] < 60).astype(int)\n",
        "    df['regra_cluster'] = df.get('suspeita_cluster', '').isin(['baixa', 'media', 'alta']).astype(int)\n",
        "\n",
        "    df = calcular_erros_e_distancias(df, modelos)\n",
        "\n",
        "    df['pontuacao_fraude'] = (\n",
        "        2 * df['regra_cluster'] +  # restaurado para peso 2\n",
        "        2 * df['regra_horario'] +\n",
        "        1 * df['regra_valor_alto'] +\n",
        "        1 * df['regra_frequencia']\n",
        "    )\n",
        "    df['fraude_confirmada'] = (df['pontuacao_fraude'] >= 3).astype(int)\n",
        "\n",
        "    # Simular 1% de falsos negativos e falsos positivos para robustez\n",
        "    n_positivos = df['fraude_confirmada'].sum()\n",
        "    n_negativos = len(df) - n_positivos\n",
        "    n_ruido = int(0.005 * len(df))  # reduzido de 1% para 0.5%\n",
        "\n",
        "    # Tornar 1% dos positivos em negativos (FN simulados)\n",
        "    positivos_idx = df[df['fraude_confirmada'] == 1].sample(n=min(n_ruido, n_positivos), random_state=42).index\n",
        "    df.loc[positivos_idx, 'fraude_confirmada'] = 0\n",
        "\n",
        "    # Tornar 1% dos negativos em positivos (FP simulados)\n",
        "    negativos_idx = df[df['fraude_confirmada'] == 0].sample(n=min(n_ruido, n_negativos), random_state=42).index\n",
        "    df.loc[negativos_idx, 'fraude_confirmada'] = 1\n",
        "\n",
        "\n",
        "\n",
        "    return df, None\n",
        "\n",
        "# ----------------------\n",
        "# Motivo do alerta\n",
        "# ----------------------\n",
        "def gerar_motivo_alerta(row):\n",
        "    motivos = []\n",
        "    if row['modelo_predito'] == 1:\n",
        "        motivos.append(\"modelo\")\n",
        "    if row['erro_reconstrucao'] > 0.1:\n",
        "        motivos.append(\"erro alto\")\n",
        "    if row['distancia_cluster'] > 10:\n",
        "        motivos.append(\"distância alta\")\n",
        "    if row['regra_valor_alto'] == 1:\n",
        "        motivos.append(\"valor alto\")\n",
        "    if row['regra_horario'] == 1:\n",
        "        motivos.append(\"horário suspeito\")\n",
        "    if row['regra_frequencia'] == 1:\n",
        "        motivos.append(\"frequência alta\")\n",
        "    if row['regra_cluster'] == 1:\n",
        "        motivos.append(\"desvio do cluster\")\n",
        "    return \", \".join(motivos) if motivos else \"sem alerta\"\n",
        "\n",
        "def aplicar_motivos_alerta(df):\n",
        "  df['motivo_alerta'] = df.apply(gerar_motivo_alerta, axis=1)\n",
        "  return df\n",
        "\n",
        "# ----------------------\n",
        "# Avaliação final de detecção\n",
        "# ----------------------\n",
        "def analisar_falsos_negativos(df):\n",
        "    falsos_negativos = df[(df['fraude_confirmada'] == 1) & (df['decisao_final'] == 0)]\n",
        "    criticos = falsos_negativos[(falsos_negativos['erro_reconstrucao'] > 0.1) | (falsos_negativos['distancia_cluster'] > 15)]\n",
        "    print(\"\\nFalsos negativos críticos:\")\n",
        "    print(criticos[['transacao_id', 'erro_reconstrucao', 'distancia_cluster']].head(10))\n",
        "    return criticos\n",
        "\n",
        "# ----------------------\n",
        "# Avaiar thresholds\n",
        "# ----------------------\n",
        "def avaliar_thresholds(modelo, X_test, y_test, grupo_test, thresholds=[0.4, 0.5, 0.55, 0.6, 0.7, 0.8]):\n",
        "    resultados = []\n",
        "    for th in thresholds:\n",
        "        pred = (modelo.predict_proba(X_test)[:, 1] >= th).astype(int)\n",
        "        f1 = f1_score(y_test, pred)\n",
        "        recall_0 = recall_score(y_test[grupo_test == 0], pred[grupo_test == 0])\n",
        "        recall_1 = recall_score(y_test[grupo_test == 1], pred[grupo_test == 1])\n",
        "        eq_op = abs(recall_0 - recall_1)\n",
        "        fn = ((y_test == 1) & (pred == 0)).sum()\n",
        "        fp = ((y_test == 0) & (pred == 1)).sum()\n",
        "        resultados.append((th, f1, recall_0, recall_1, eq_op, fn, fp))\n",
        "        print(f\"\\n Threshold {th:.2f}\")\n",
        "        print(f\"F1-score: {f1:.4f} | Equality of Opportunity: {eq_op:.4f}\")\n",
        "        print(f\"Recall grupo 0: {recall_0:.4f} | Recall grupo 1: {recall_1:.4f}\")\n",
        "        print(f\"Falsos negativos: {fn} | Falsos positivos: {fp}\")\n",
        "\n",
        "       # Diagnóstico\n",
        "    print(\"\\nThresholds:\", [r[0] for r in resultados])\n",
        "    print(\"F1 Scores:\", [r[1] for r in resultados])\n",
        "    print(\"Equality of Opportunity:\", [r[4] for r in resultados])\n",
        "\n",
        "    thresholds_plot = [r[0] for r in resultados]\n",
        "    f1_scores = [r[1] for r in resultados]\n",
        "    eq_op_scores = [r[4] for r in resultados]\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(thresholds_plot, f1_scores, label='F1-score', marker='o')\n",
        "    plt.plot(thresholds_plot, eq_op_scores, label='Equality of Opportunity', marker='x')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('F1-score e Equality of Opportunity por Threshold')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ----------------------\n",
        "# Validação temporal (exemplo de separação por mês)\n",
        "# ----------------------\n",
        "def validacao_temporal(df, modelo, modelos, grupo_col):\n",
        "    df['transacao_data'] = pd.to_datetime(df['transacao_data'])\n",
        "    df['mes'] = df['transacao_data'].dt.to_period('M')\n",
        "    meses = sorted(df['mes'].unique())\n",
        "    resultados_mensais = []\n",
        "\n",
        "    for i in range(len(meses) - 1):\n",
        "        treino = df[df['mes'] <= meses[i]]\n",
        "        teste = df[df['mes'] == meses[i+1]]\n",
        "\n",
        "        if len(treino) < 1000 or len(teste) < 1000:\n",
        "            continue\n",
        "\n",
        "        X_treino = treino[modelos['colunas_scaler']]\n",
        "        y_treino = treino['fraude_confirmada']\n",
        "        X_teste = teste[modelos['colunas_scaler']]\n",
        "        y_teste = teste['fraude_confirmada']\n",
        "        grupo_teste = teste[grupo_col]\n",
        "\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_res, y_res = smote.fit_resample(X_treino, y_treino)\n",
        "        modelo.fit(X_res, y_res)\n",
        "\n",
        "        print(f\"\\nValidação mês: {meses[i+1]}\")\n",
        "        avaliar_thresholds(modelo, X_teste, y_teste, grupo_teste)\n",
        "        resultados_mensais.append((meses[i+1], modelo.score(X_teste, y_teste)))\n",
        "\n",
        "    return resultados_mensais\n",
        "\n",
        "\n",
        "def gerar_score_continuo(df):\n",
        "    df['score_final'] = (\n",
        "        df['modelo_predito'] * 0.5 +\n",
        "        df['regra_valor_alto'] * 0.2 +\n",
        "        df['regra_horario'] * 0.2 +\n",
        "        df['regra_frequencia'] * 0.1\n",
        "    )\n",
        "    df['score_final'] = df['score_final'] / df['score_final'].max()\n",
        "\n",
        "    df['faixa_risco'] = pd.cut(\n",
        "        df['score_final'],\n",
        "        bins=[-0.01, 0.4, 0.7, 1.0],\n",
        "        labels=['baixo', 'moderado', 'alto']\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# ----------------------\n",
        "# Execução principal\n",
        "# ----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv(\"/content/transacoes_com_comportamento_por_conta.csv\")\n",
        "    df['transacao_data'] = pd.to_datetime(df['transacao_data'])\n",
        "\n",
        "    modelos = carregar_modelos()\n",
        "    df, _ = detectar_anomalias(df, modelos)\n",
        "\n",
        "    df['mesma_titularidade'] = df['mesma_titularidade'].astype(int)\n",
        "    grupo_sensivel = df['mesma_titularidade'].copy()\n",
        "\n",
        "    colunas_validas = [\n",
        "        'transacao_valor', 'fim_de_semana',\n",
        "        'transacao_tipo_pix', 'transacao_tipo_transferencia',\n",
        "        'erro_reconstrucao', 'distancia_cluster','mesma_titularidade', 'faixa_horaria_Madrugada',\n",
        "        'dia_de_semana_Sabado', 'dia_de_semana_Domingo'\n",
        "    ]\n",
        "\n",
        "    X = df[colunas_validas]\n",
        "    y = df['fraude_confirmada']\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "    fator_repeticao = int(np.ceil(len(y_res) / len(grupo_sensivel)))\n",
        "    grupo_expandido = pd.Series(np.tile(grupo_sensivel.values, fator_repeticao)[:len(y_res)], name=\"grupo\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test, grupo_train, grupo_test = train_test_split(\n",
        "        X_res, y_res, grupo_expandido, test_size=0.3, random_state=42\n",
        "    )\n",
        "\n",
        "    modelo_final = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    modelo_final.fit(X_train, y_train)\n",
        "\n",
        "    for threshold in [0.6, 0.4]:\n",
        "        print(f\"\\n📊 Avaliação com Threshold {threshold:.2f}\")\n",
        "        df[f'modelo_predito_{int(threshold*100)}'] = (modelo_final.predict_proba(X)[:, 1] >= threshold).astype(int)\n",
        "\n",
        "        df['regra_alerta'] = (\n",
        "            (df['transacao_valor'] > 0.8) &\n",
        "            (df['fim_de_semana'] == 1) &\n",
        "            (df['mesma_titularidade'] == 0) &\n",
        "            (df['faixa_horaria_Madrugada'] == 1)\n",
        "        )\n",
        "\n",
        "        df[f'decisao_final_{int(threshold*100)}'] = (\n",
        "            (df[f'modelo_predito_{int(threshold*100)}'] == 1) | df['regra_alerta']\n",
        "        ).astype(int)\n",
        "\n",
        "        total = df['fraude_confirmada'].sum()\n",
        "        fn = ((df['fraude_confirmada'] == 1) & (df[f'decisao_final_{int(threshold*100)}'] == 0)).sum()\n",
        "        fp = ((df['fraude_confirmada'] == 0) & (df[f'decisao_final_{int(threshold*100)}'] == 1)).sum()\n",
        "        acertos = ((df['fraude_confirmada'] == df[f'decisao_final_{int(threshold*100)}'])).sum()\n",
        "\n",
        "        print(f\"Total fraudes (threshold {threshold}):\", total)\n",
        "        print(\"Falsos negativos:\", fn)\n",
        "        print(\"Falsos positivos:\", fp)\n",
        "        print(\"Acertos:\", acertos)\n",
        "\n",
        "\n",
        "    df['modelo_predito'] = (modelo_final.predict_proba(X)[:, 1] >= 0.6).astype(int)\n",
        "    df['regra_alerta'] = (\n",
        "        (df['transacao_valor'] > 0.8) &\n",
        "        (df['fim_de_semana'] == 1) &\n",
        "        (df['mesma_titularidade'] == 0) &\n",
        "        (df.get('faixa_horaria_Madrugada', 0) == 1)\n",
        "    )\n",
        "    df['decisao_final'] = ((df['modelo_predito'] == 1) | (df['regra_alerta'])).astype(int)\n",
        "\n",
        "    df['nivel_suspeita'] = np.select(\n",
        "        [\n",
        "            (df['erro_reconstrucao'] > 0.2) & (df['distancia_cluster'] > 15),\n",
        "            (df['erro_reconstrucao'] > 0.1) | (df['distancia_cluster'] > 10),\n",
        "            (df['modelo_predito'] == 1)\n",
        "        ],\n",
        "        ['alta', 'media', 'baixa'],\n",
        "        default='nenhuma'\n",
        "    )\n",
        "\n",
        "    df['risco_critico'] = (\n",
        "        (df['fraude_confirmada'] == 1) &\n",
        "        (df['decisao_final'] == 0) &\n",
        "        ((df['erro_reconstrucao'] > 0.1) | (df['distancia_cluster'] > 10))\n",
        "    ).astype(int)\n",
        "\n",
        "    transacoes_anomalas = df[df['decisao_final'] == 1]\n",
        "    print(transacoes_anomalas.head(10))\n",
        "\n",
        "    colunas_chave = [\n",
        "        'transacao_id', 'cliente_id', 'conta_id', 'transacao_valor',\n",
        "        'transacao_data', 'modelo_predito', 'regra_valor_alto',\n",
        "        'regra_horario', 'regra_frequencia', 'regra_cluster', 'decisao_final',\n",
        "        'erro_reconstrucao', 'distancia_cluster', 'nivel_suspeita'\n",
        "    ]\n",
        "    print(transacoes_anomalas[colunas_chave].head(10))\n",
        "\n",
        "    print(f\"Total de transações anômalas detectadas: {len(transacoes_anomalas)}\")\n",
        "\n",
        "    avaliar_thresholds(modelo_final, X_test, y_test, grupo_test, thresholds=[0.4, 0.5, 0.55, 0.6, 0.7, 0.8])\n",
        "    validacao_temporal(df, modelo_final, modelos, 'mesma_titularidade')\n",
        "    df.to_csv(\"transacoes_analisadas.csv\", index=False)\n",
        "\n",
        "    # Salvar o modelo XGBoost treinado para uso futuro\n",
        "    joblib.dump(modelo_final, \"modelos/modelo_xgb.pkl\")\n",
        "    print(\"💾 Modelo XGBoost salvo com sucesso em 'modelos/modelo_xgb.pkl'.\")\n",
        "\n",
        "    transacoes_anomalas[colunas_chave].to_csv(\"transacoes_anomalas_log.csv\", index=False)\n",
        "    print(\"\\n📁 Arquivo 'transacoes_anomalas_log.csv' salvo com sucesso.\")"
      ],
      "metadata": {
        "id": "-A1yTIBPFG8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Avaliação combinada: modelo + regras\n",
        "# ----------------------\n",
        "total_fraudes = df['fraude_confirmada'].sum()\n",
        "falsos_negativos = ((df['fraude_confirmada'] == 1) & (df['decisao_final'] == 0)).sum()\n",
        "falsos_positivos = ((df['fraude_confirmada'] == 0) & (df['decisao_final'] == 1)).sum()\n",
        "acertos = ((df['fraude_confirmada'] == df['decisao_final'])).sum()\n",
        "\n",
        "print(\"\\nAvaliação Final de Detecção de Fraudes\")\n",
        "print(f\"Total de fraudes reais no conjunto: {total_fraudes}\")\n",
        "print(f\"Falsos Negativos (fraudes não detectadas): {falsos_negativos}\")\n",
        "print(f\"Falsos Positivos (falsos alarmes): {falsos_positivos}\")\n",
        "print(f\"Acertos (decisão correta): {acertos}\")\n",
        "\n",
        "total_fraudes_40 = df['fraude_confirmada'].sum()\n",
        "falsos_negativos_40 = ((df['fraude_confirmada'] == 1) & (df['decisao_final_40'] == 0)).sum()\n",
        "falsos_positivos_40 = ((df['fraude_confirmada'] == 0) & (df['decisao_final_40'] == 1)).sum()\n",
        "acertos_40 = ((df['fraude_confirmada'] == df['decisao_final_40'])).sum()\n",
        "\n",
        "print(\"\\n📊 Avaliação Final de Detecção de Fraudes (Threshold 0.40)\")\n",
        "print(f\"Total de fraudes reais no conjunto: {total_fraudes_40}\")\n",
        "print(f\"Falsos Negativos (anomalias não detectadas): {falsos_negativos_40}\")\n",
        "print(f\"Falsos Positivos (falsos alarmes): {falsos_positivos_40}\")\n",
        "print(f\"Acertos (decisão correta): {acertos_40}\")"
      ],
      "metadata": {
        "id": "lR3MA2MtqW6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OqvSQkXWolN-PsYYciPRJTYku4sfF6kE",
      "authorship_tag": "ABX9TyO7oRv9RdRuM/9S78o7FD3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}